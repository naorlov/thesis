\documentclass[conference]{IEEEtran} \IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote.
% If that is unneeded, please comment it out.
\usepackage{amsmath,amssymb,amsfonts} \usepackage{algorithmic}
\usepackage{graphicx} \usepackage{textcomp} \usepackage{xcolor}
\usepackage{icomma}
% \def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
% T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}


\usepackage[backend=bibtex]{biblatex}

\addbibresource{bibliography.bib}

\newcommand*{\TODO}[1]{{\color{red}{TODO: \textit{#1}}}}


\newtheorem{oldlem}{Лемма}[section] \newenvironment{lemma}[1][]
{\begin{oldlem}[#1]} {\end{oldlem}}

\newtheorem{olddefi}[oldlem]{Definition} \newenvironment{definition}[1][]
{\begin{olddefi}\normalfont} {\end{olddefi}}


\begin{document} \title{DRAFT: Simulating execution of MapReduce applications}

    \author{ 
        \IEEEauthorblockN{Nikita Orlov} 
        \IEEEauthorblockA{ 
            \textit{Higher School of Economics} \\ 
            Moscow, Russia \\ 
            naorlov\_1@edu.hse.ru 
        } 
    }

    \maketitle

    \begin{abstract} 
        A new method of MapReduce simulation is proposed combining event-discrete simulatros and analytical models, that are built on the fly from data, gathered with a help of performance benchmarks.
    \end{abstract}

    \begin{IEEEkeywords} 
        MapReduce, simulation, analytical model, event discrete simulator
    \end{IEEEkeywords}

    \section{Introduction} 


    Since Google released a paper on the MapReduce framework \cite{google_mapreduce}, a considerable amount of research was put on developing systems that store, process, and transform a significant amount of data. Today, big companies are producing hundreds of terabytes of data on a daily basis. 



    The specific objective of this study is to build an open-source platform to perform a cluster simulation with given hardware and software parameters.

    Several papers are released on this topic, but they do not provide any code or did not updated for a couple of years and are outdated. Having such an instrument that can accurately predict execution time can be useful in some situations. TODO(citation). 

    This study is aimed to simulate and predict execution times for a homogenous MapReduce cluster. No assumption is made about input mappers and reducers, their input and output data distribution. However, cluster homogeneity is assumed.

    \section{Literature review} 
    \label{literature_review} 


    For the past decade, several studies have proposed techniques to build a MapReduce simulator. They can be differentiated by the simulation method. 

    Discrete-event modelling is a method that represents the system's operation in a system as an ordered list of events in a system. Every event contains its timestamp, representing event time at which event took place. The simulation engine algorithm is straightforward: it sets the current time to 0 and iterates over a set of events, on each step advancing current time. When the simulation is completed, the engine reports a total simulation time, as well as several statistics. While using this method, researches can balance between simulation time and simulation accuracy - describing more aspects of a system leads to an increase in overall run time. In contrast, this time can be reduced by decreasing the "resolution" of simulation (i.e., the number of entities, internal framework processes).

    ROSS (Rensselaer Optimistic Simulation System) is an example of parallel discrete-event simulator. It is used by CODES as an essential event modelling framework. CODES itself is an I/O and storage emulator that allows building an accurate emulation of exascale storage solutions.

    Analytical modelling is a method that uses a set of performance equations that can predict the system's performance. 

    Some existing simulators are based on discrete-event modelling, like Mumak, SimMR, MRperf, MRSG and MRsim. 

    In contrary, Starfish is based on analytical modelling technique.

    Another way to differentiate is to consider a system design and simulation scope: Mumak and SLS are scheduler simulators, and MRperf, MRSG and MRsim are task execution engine simulators.


    \section{Methods} 


    This project uses a mix of two approaches given in previous section.

    First, a binary is tested to obtain performance statistics. The program is run ten times. Each time several parameters are recorded, including but not limited to total execution time, maximum memory use, input, and output data size.

    \begin{definition}
        \textit{Complexity function} for a given executable program is a function that maps input size in bytes and lines to overall execution time, RAM usage, output file size in bytes and rows.
    \end{definition}

    Then this data is passed to the \textit{Morpheus} analytics system. It builds complexity functions for a given executable file. Then, all the gathered data is split between a training set and a validation set. For the given assumptions in previous sections, the Lambda algorithm is used.

    \textit{Lambda} algorithm is proposed to find an analytical model for input/output parameters relationship. Since all tested programs are mappers and reducers, their complexity functions can be written as follows:

    \begin{equation} 
        f(n) = \sum_{i = 1}^d a_in^i + \sum_{i=1}^d b_in^i\log(n) + c 
    \end{equation} 

    where $a_i, b_i, c \in \mathbb{R}$, $d$ -- polynomial degree.

    For any reasonable purposes, we can assume ​.

    We could use Lagrange polynomial (citation) to obtain a minimal polynomial that is fitted to given points, but we cannot get a suitable polynomial to extrapolate this function. For example, if we have a quadratic function and we sample 6 points from it, we will get a 6-degree polynomial. Instead, all possible combinations of the base polynomial are used to fit a linear regression on their associative coefficients. Then a model with the best metrics on validation data is chosen. This model is then treated as a complexity function.

    Then the analytical model is used in simulation agents of SimGrid framework to tell precisely the amount of operations needed to be performed, and the amount of data is produced.

    Simulation agents are programmed to perform all steps of MapReduce operation, as described in \cite{baseline_model}.
        

    \section{Results anticipated}

    It is hoped that the end result of this study will be a complete MapReduce simulation solution, that will be capable of evaluating the performance of a MapReduce pipeline executed on large data processing clusters. A number of Resulting toolchain will be compared and tested against other available MapReduce simulators to reveal any possible advantages and disadvantages for the system. Finally, a number of popular MapReduce algorithms will be used to compare the overall system's accuracy and real execution time on a real cluster. 

    \printbibliography

\end{document}


